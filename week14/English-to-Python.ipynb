{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END Week 14 - Copy of English to Python with gensim v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "54981b346ba7401a933c622161988df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_11199ebb44bf482e9d2689390cbc85a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ade345d01824c97a9e86e318b8ae73f",
              "IPY_MODEL_77cc0e5696c74d6abb05d2e9e405948d"
            ]
          }
        },
        "11199ebb44bf482e9d2689390cbc85a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ade345d01824c97a9e86e318b8ae73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_07c1efd3406844989f6b5ecfbd9e6a34",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10034,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10034,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3fe2810c85a54fb899ad9b66fbcb3e75"
          }
        },
        "77cc0e5696c74d6abb05d2e9e405948d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0f7a05f3bb124dcca317398d615255ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10034/10034 [20:58&lt;00:00,  7.97it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ae8fc5f305943dfa0e7b16c25eda0f7"
          }
        },
        "07c1efd3406844989f6b5ecfbd9e6a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3fe2810c85a54fb899ad9b66fbcb3e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f7a05f3bb124dcca317398d615255ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ae8fc5f305943dfa0e7b16c25eda0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumarchandan/END/blob/main/week14/English-to-Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlv7IfhFQhsv"
      },
      "source": [
        "# Data Perparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-mOljzdcIZL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "import spacy\n",
        "import gensim\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import tokenize\n",
        "import re\n",
        "import pandas as pd\n",
        "import csv\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5WZWgUq7N0Qn",
        "outputId": "8f00bec3-c615-4621-d53d-bbc7b4e0d80e"
      },
      "source": [
        "torchtext.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.9.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnvuehOPVoHM"
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCx1Pa9uVqcO",
        "outputId": "9f760d1d-3b1f-4fbb-b71c-317dcfe24799"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1UTpnAaSUlp"
      },
      "source": [
        "## Reading the text file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYRncG2sPvbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5993cb82-2a1b-4d93-c91e-1259d283d966"
      },
      "source": [
        "corpus_name = 'english-python'\n",
        "corpus = os.path.join('/content/drive/MyDrive/1-Projects/END/week14/', corpus_name)\n",
        "\n",
        "def printLines(file,):\n",
        "  count = 0\n",
        "  with open(file, 'rb') as f:\n",
        "    for line in f:\n",
        "      print(line)\n",
        "      count += 1\n",
        "      if count == 10: break\n",
        "\n",
        "printLines(os.path.join(corpus, 'data_refined_v1.txt'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'# write a python program to add two numbers\\n'\n",
            "b'num1 = 1.5\\n'\n",
            "b'num2 = 6.3\\n'\n",
            "b'sum = num1 + num2\\n'\n",
            "b\"print(f'Sum: {sum}')\\n\"\n",
            "b'\\n'\n",
            "b'\\n'\n",
            "b'# write a python function to add two user provided numbers and return the sum\\n'\n",
            "b'def add_two_numbers(num1, num2):\\n'\n",
            "b'    sum = num1 + num2\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcPoWVXRYqbT"
      },
      "source": [
        "corpus_name = 'english-python'\n",
        "corpus = os.path.join('/content/drive/MyDrive/1-Projects/END/week14/', corpus_name)\n",
        "\n",
        "def extractQnAPair(file):\n",
        "  qna_pair_list = []\n",
        "  qna_pair = { 'src': '', 'trg': ''}\n",
        "  count = 0\n",
        "  regex = r\"#\"\n",
        "  str = ''\n",
        "  with open(file, 'r') as f:\n",
        "    for line in f:\n",
        "      line = line.lower()\n",
        "      line = re.sub(r'\"#[0123456789]','#', line)\n",
        "      line = line.replace(\"\\n\\n\",\"\\n\")\n",
        "      line = line.replace(\"\\n\\n\\n\",\"\\n\\n\")\n",
        "      ques_found = re.search(regex, line)\n",
        "      if ques_found:\n",
        "        if (qna_pair['src'] and qna_pair['trg']): qna_pair_list.append(qna_pair)\n",
        "        qna_pair = { 'src': '', 'trg': ''}\n",
        "        qna_pair['id'] = count\n",
        "        qna_pair['src'] = line\n",
        "        qna_pair['trg'] = ''\n",
        "        count += 1\n",
        "      else:\n",
        "        qna_pair['trg'] += line\n",
        "  return qna_pair_list\n",
        "\n",
        "qna_pair_list = extractQnAPair(os.path.join(corpus, 'data_refined_v1.txt'))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "496BinUxV7U5",
        "outputId": "ec739b78-f289-406c-f1cd-a70fe48d27a0"
      },
      "source": [
        "len(qna_pair_list), qna_pair_list[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4445,\n",
              " {'id': 0,\n",
              "  'src': '# write a python program to add two numbers\\n',\n",
              "  'trg': \"num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\nprint(f'Sum: {sum}')\\n\\n\\n\"})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xxYB2IRjbKY"
      },
      "source": [
        "Create a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "1M81ys0DjS1r",
        "outputId": "b30740aa-8ed0-49d9-fc09-d211c02f5fb3"
      },
      "source": [
        "df = pd.DataFrame(qna_pair_list)\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>trg</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td># write a python program to add two numbers\\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td># write a python function to add two user prov...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td># write a program to find and print the larges...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;= n...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td># write a program to find and print the smalle...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td># Write a python function to merge two given l...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 src  ... id\n",
              "0      # write a python program to add two numbers\\n  ...  0\n",
              "1  # write a python function to add two user prov...  ...  1\n",
              "2  # write a program to find and print the larges...  ...  2\n",
              "3  # write a program to find and print the smalle...  ...  3\n",
              "4  # Write a python function to merge two given l...  ...  4\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVduEzbFV-Th"
      },
      "source": [
        "# print(qna_pair_list[0].keys()) # dict_keys(['question_id', 'question', 'answer'])\n",
        "keys = qna_pair_list[0].keys()\n",
        "\n",
        "shouldExecute = True\n",
        "if shouldExecute:\n",
        "  with open('python_qna.csv', 'w', newline='') as output_file:\n",
        "    dict_writer = csv.DictWriter(output_file, keys)\n",
        "    dict_writer.writeheader()\n",
        "    dict_writer.writerows(qna_pair_list)\n",
        "else:\n",
        "  print('did not execute')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XncIv8MrWW22",
        "outputId": "c7151be7-3a19-4d09-c295-7e512068c559"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.1.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx240Td3WZYQ"
      },
      "source": [
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcyjL5buWlbi"
      },
      "source": [
        "def tokenize_en(text):\n",
        "    \"\"\"\n",
        "    Tokenizes English text from a string into a list of strings\n",
        "    \"\"\"\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhWPlLpBWodV"
      },
      "source": [
        "SRC = Field(tokenize = 'spacy', \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "TRG = Field(tokenize = 'spacy', \n",
        "            init_token = '<sos>', \n",
        "            eos_token = '<eos>', \n",
        "            lower = True, \n",
        "            batch_first = True)\n",
        "\n",
        "fields = [(\"src\", SRC), (\"trg\", TRG)]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v06UtHyjWHrJ"
      },
      "source": [
        "dataset = TabularDataset(\n",
        "    path='python_qna.csv',\n",
        "    format='csv',\n",
        "    fields=fields,\n",
        "    skip_header=True\n",
        ")\n",
        "(train_data, valid_data) = dataset.split(split_ratio=[0.85, 0.15])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzTBHmpkW79R",
        "outputId": "265de855-2e7e-454e-a4fa-6105dd1fac25"
      },
      "source": [
        "vars(train_data[0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['#',\n",
              "  'write',\n",
              "  'a',\n",
              "  'python',\n",
              "  'program',\n",
              "  'to',\n",
              "  'print',\n",
              "  'the',\n",
              "  'character',\n",
              "  'of',\n",
              "  'an',\n",
              "  'ascii',\n",
              "  'value'],\n",
              " 'trg': ['value',\n",
              "  '=',\n",
              "  '65',\n",
              "  '\\n',\n",
              "  \"print(f'the\",\n",
              "  'ascii',\n",
              "  'value',\n",
              "  '{',\n",
              "  'value',\n",
              "  '}',\n",
              "  'is',\n",
              "  'of',\n",
              "  'the',\n",
              "  'character',\n",
              "  '{',\n",
              "  'chr(value',\n",
              "  ')',\n",
              "  '}',\n",
              "  \"'\",\n",
              "  ')']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdk7rek4XEbS"
      },
      "source": [
        "To decide maxlength for encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGpviy25W_6W",
        "outputId": "7a80c927-73f0-4df3-c024-fafa053c3361"
      },
      "source": [
        "max_len_src = 0\n",
        "max_len_trg = 0\n",
        "\n",
        "for data in train_data:\n",
        "  if len(data.src) > max_len_src:\n",
        "    max_len_src = len(data.src)\n",
        "  if len(data.trg) > max_len_trg:\n",
        "    max_len_trg = len(data.trg)\n",
        "\n",
        "max_len_src, max_len_trg"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(84, 488)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJrmd75IXHk0"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KolQ_bROXVaW",
        "outputId": "3aade770-0bff-4557-cd78-98797fcfcd26"
      },
      "source": [
        "print('Source vocab size: ', len(SRC.vocab))\n",
        "print('Target vocab size: ', len(TRG.vocab))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source vocab size:  1510\n",
            "Target vocab size:  10034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB0xXHJpXOPD",
        "outputId": "28038a95-bf52-4479-f8c8-c567b64d3a4e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_6uDZhJXnr5"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "     batch_size = BATCH_SIZE,\n",
        "     sort=False,\n",
        "     device = device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vm_ylkdZXx-o",
        "outputId": "e0c7fb4a-62d4-4760-f60b-4d8600c020a0"
      },
      "source": [
        "vars(train_iterator.dataset.examples[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'src': ['#',\n",
              "  'write',\n",
              "  'a',\n",
              "  'python',\n",
              "  'program',\n",
              "  'to',\n",
              "  'print',\n",
              "  'the',\n",
              "  'character',\n",
              "  'of',\n",
              "  'an',\n",
              "  'ascii',\n",
              "  'value'],\n",
              " 'trg': ['value',\n",
              "  '=',\n",
              "  '65',\n",
              "  '\\n',\n",
              "  \"print(f'the\",\n",
              "  'ascii',\n",
              "  'value',\n",
              "  '{',\n",
              "  'value',\n",
              "  '}',\n",
              "  'is',\n",
              "  'of',\n",
              "  'the',\n",
              "  'character',\n",
              "  '{',\n",
              "  'chr(value',\n",
              "  ')',\n",
              "  '}',\n",
              "  \"'\",\n",
              "  ')']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzXYkxNNYCLM"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W4664edYBdA"
      },
      "source": [
        "def tokenize_code(text):\n",
        "    \"\"\"\n",
        "    Replace and Tokenize\n",
        "    \"\"\"\n",
        "    text = str(text).replace('\\n', '\\t\\t')\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVSle5SUkYGU"
      },
      "source": [
        "https://medium.com/@rohit_agrawal/using-fine-tuned-gensim-word2vec-embeddings-with-torchtext-and-pytorch-17eea2883cd"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udy74YZcZJKp"
      },
      "source": [
        "# WORD2VEC\n",
        "W2V_SIZE = 256\n",
        "W2V_WINDOW = 3\n",
        "# W2V_EPOCH = 100\n",
        "W2V_MIN_COUNT = 2\n",
        "\n",
        "target = []\n",
        "for code in df['trg'].values:\n",
        "  code_token = tokenize_code(code)\n",
        "  target.append(code_token)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3-guwoEj-BY",
        "outputId": "d27feb24-b833-40c1-b2c9-4ca9e06ca391"
      },
      "source": [
        "target[:1]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['num1',\n",
              "  '=',\n",
              "  '1.5',\n",
              "  '\\t\\t',\n",
              "  'num2',\n",
              "  '=',\n",
              "  '6.3',\n",
              "  '\\t\\t',\n",
              "  'sum',\n",
              "  '=',\n",
              "  'num1',\n",
              "  '+',\n",
              "  'num2',\n",
              "  '\\t\\t',\n",
              "  \"print(f'Sum\",\n",
              "  ':',\n",
              "  '{',\n",
              "  'sum',\n",
              "  '}',\n",
              "  \"'\",\n",
              "  ')',\n",
              "  '\\t\\t\\t\\t\\t\\t']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVkKrTbgj9ED"
      },
      "source": [
        "w2v_model = gensim.models.Word2Vec(target, size=W2V_SIZE, window=W2V_WINDOW, min_count=W2V_MIN_COUNT)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203,
          "referenced_widgets": [
            "54981b346ba7401a933c622161988df9",
            "11199ebb44bf482e9d2689390cbc85a2",
            "8ade345d01824c97a9e86e318b8ae73f",
            "77cc0e5696c74d6abb05d2e9e405948d",
            "07c1efd3406844989f6b5ecfbd9e6a34",
            "3fe2810c85a54fb899ad9b66fbcb3e75",
            "0f7a05f3bb124dcca317398d615255ff",
            "9ae8fc5f305943dfa0e7b16c25eda0f7"
          ]
        },
        "id": "ufiMCNDNlv-K",
        "outputId": "20395f9d-0393-4493-fd3d-1b26e0c25a90"
      },
      "source": [
        "word2vec_vectors = []\n",
        "\n",
        "for token, idx in tqdm_notebook(TRG.vocab.stoi.items()):\n",
        "  if token in w2v_model.wv.vocab.keys():\n",
        "    word2vec_vectors.append(torch.FloatTensor(w2v_model[token]))\n",
        "  else:\n",
        "    word2vec_vectors.append(torch.zeros(W2V_SIZE))\n",
        "\n",
        "TRG.vocab.set_vectors(TRG.vocab.stoi, word2vec_vectors, W2V_SIZE)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54981b346ba7401a933c622161988df9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10034.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmSKvM7Mnfi5"
      },
      "source": [
        "w2v_model.save('code_embeddings.txt')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgvD_MpkC2OS"
      },
      "source": [
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-encoder.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE6JimgOCz-w"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 input_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim,\n",
        "                 dropout, \n",
        "                 device,\n",
        "                 max_length = 250):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        \n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim,\n",
        "                                                  dropout, \n",
        "                                                  device) \n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "        \n",
        "        #pos = [batch size, src len]\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        #src = [batch size, src len, hid dim]\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LheiXWVFDEg"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        #src_mask = [batch size, 1, 1, src len] \n",
        "                \n",
        "        #self attention\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        \n",
        "        #src = [batch size, src len, hid dim]\n",
        "        \n",
        "        return src"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9w9xDUKL7LU"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "        \n",
        "        #x = [batch size, seq len, pf dim]\n",
        "        \n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        #x = [batch size, seq len, hid dim]\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZmeHfGhGzkN"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0\n",
        "        \n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads\n",
        "        \n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "        \n",
        "        #query = [batch size, query len, hid dim]\n",
        "        #key = [batch size, key len, hid dim]\n",
        "        #value = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "        \n",
        "        #Q = [batch size, query len, hid dim]\n",
        "        #K = [batch size, key len, hid dim]\n",
        "        #V = [batch size, value len, hid dim]\n",
        "                \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        \n",
        "        #Q = [batch size, n heads, query len, head dim]\n",
        "        #K = [batch size, n heads, key len, head dim]\n",
        "        #V = [batch size, n heads, value len, head dim]\n",
        "                \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        \n",
        "        #energy = [batch size, n heads, query len, key len]\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)\n",
        "                \n",
        "        #attention = [batch size, n heads, query len, key len]\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "        \n",
        "        #x = [batch size, n heads, query len, head dim]\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        \n",
        "        #x = [batch size, query len, n heads, head dim]\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        #x = [batch size, query len, hid dim]\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBFqGg5z-o_r"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbTr7YPSMRpC"
      },
      "source": [
        "![](https://raw.githubusercontent.com/bentrevett/pytorch-seq2seq/9479fcb532214ad26fd4bda9fcf081a05e1aaf4e/assets/transformer-decoder.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBMMF45MMNS"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, \n",
        "                 output_dim, \n",
        "                 hid_dim, \n",
        "                 n_layers, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device,\n",
        "                 pre_trained_emb,\n",
        "                 max_length = 500):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device\n",
        "        \n",
        "        # self.pre_trained_emb = pre_trained_emb\n",
        "        self.tok_embedding = nn.Embedding.from_pretrained(pre_trained_emb)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
        "                                                  n_heads, \n",
        "                                                  pf_dim, \n",
        "                                                  dropout, \n",
        "                                                  device)\n",
        "                                     for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "                            \n",
        "        #pos = [batch size, trg len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "                \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMEr1IFUMxco"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim, \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
        "                                                                     pf_dim, \n",
        "                                                                     dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        \n",
        "        #self attention\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "            \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "            \n",
        "        #encoder attention\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "        # query, key, value\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "                    \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        \n",
        "        #positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "        \n",
        "        #dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "        \n",
        "        #trg = [batch size, trg len, hid dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3Mg8OGN6ul"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, \n",
        "                 encoder, \n",
        "                 decoder, \n",
        "                 src_pad_idx, \n",
        "                 trg_pad_idx, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "        \n",
        "    def make_src_mask(self, src):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg):\n",
        "        \n",
        "        #trg = [batch size, trg len]\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        \n",
        "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
        "        \n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "        \n",
        "        #trg_sub_mask = [trg len, trg len]\n",
        "            \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        \n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \n",
        "        #src = [batch size, src len]\n",
        "        #trg = [batch size, trg len]\n",
        "                \n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        \n",
        "        #src_mask = [batch size, 1, 1, src len]\n",
        "        #trg_mask = [batch size, 1, trg len, trg len]\n",
        "        \n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        \n",
        "        #enc_src = [batch size, src len, hid dim]\n",
        "                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        #output = [batch size, trg len, output dim]\n",
        "        #attention = [batch size, n heads, trg len, src len]\n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvrK6zbF_2Fs"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zsZjSSWOSHc"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "pre_trained_emb = torch.FloatTensor(TRG.vocab.vectors)\n",
        "\n",
        "enc = Encoder(INPUT_DIM, \n",
        "              HID_DIM, \n",
        "              ENC_LAYERS, \n",
        "              ENC_HEADS, \n",
        "              ENC_PF_DIM, \n",
        "              ENC_DROPOUT, \n",
        "              device)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM,\n",
        "              HID_DIM,\n",
        "              DEC_LAYERS,\n",
        "              DEC_HEADS,\n",
        "              DEC_PF_DIM,\n",
        "              DEC_DROPOUT,\n",
        "              device,\n",
        "              pre_trained_emb)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSvrFtyQukr-"
      },
      "source": [
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qd0ePzj0OzLa",
        "outputId": "71810a71-1145-4d29-c769-227d51cc3db0"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 7,110,962 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZ0hyo8O0vE"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRtAM9Y4O2N2"
      },
      "source": [
        "model.apply(initialize_weights);"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEpApG3YO3ZE"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYT55TZFu3jj"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31-umOq6vDGK"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    for i, batch in enumerate(iterator):\n",
        "        \n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])\n",
        "                \n",
        "        #output = [batch size, trg len - 1, output dim]\n",
        "        #trg = [batch size, trg len]\n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                \n",
        "        #output = [batch size * trg len - 1, output dim]\n",
        "        #trg = [batch size * trg len - 1]\n",
        "            \n",
        "        loss = criterion(output, trg)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi3Ev8gaO79_"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for i, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])\n",
        "            \n",
        "            #output = [batch size, trg len - 1, output dim]\n",
        "            #trg = [batch size, trg len]\n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            \n",
        "            #output = [batch size * trg len - 1, output dim]\n",
        "            #trg = [batch size * trg len - 1]\n",
        "            \n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuB4JqQRO9Wg"
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aax76Ie4O_Cr",
        "outputId": "8961cb4b-6641-4e2f-c698-9753b7bfea51"
      },
      "source": [
        "N_EPOCHS = 50\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 17s\n",
            "\tTrain Loss: 4.700 | Train PPL: 109.902\n",
            "\t Val. Loss: 3.833 |  Val. PPL:  46.209\n",
            "Epoch: 02 | Time: 0m 16s\n",
            "\tTrain Loss: 3.564 | Train PPL:  35.295\n",
            "\t Val. Loss: 3.344 |  Val. PPL:  28.342\n",
            "Epoch: 03 | Time: 0m 16s\n",
            "\tTrain Loss: 3.114 | Train PPL:  22.510\n",
            "\t Val. Loss: 3.071 |  Val. PPL:  21.563\n",
            "Epoch: 04 | Time: 0m 16s\n",
            "\tTrain Loss: 2.767 | Train PPL:  15.903\n",
            "\t Val. Loss: 2.854 |  Val. PPL:  17.363\n",
            "Epoch: 05 | Time: 0m 16s\n",
            "\tTrain Loss: 2.474 | Train PPL:  11.869\n",
            "\t Val. Loss: 2.695 |  Val. PPL:  14.804\n",
            "Epoch: 06 | Time: 0m 16s\n",
            "\tTrain Loss: 2.226 | Train PPL:   9.260\n",
            "\t Val. Loss: 2.584 |  Val. PPL:  13.252\n",
            "Epoch: 07 | Time: 0m 16s\n",
            "\tTrain Loss: 2.007 | Train PPL:   7.438\n",
            "\t Val. Loss: 2.452 |  Val. PPL:  11.610\n",
            "Epoch: 08 | Time: 0m 16s\n",
            "\tTrain Loss: 1.822 | Train PPL:   6.187\n",
            "\t Val. Loss: 2.388 |  Val. PPL:  10.897\n",
            "Epoch: 09 | Time: 0m 16s\n",
            "\tTrain Loss: 1.670 | Train PPL:   5.311\n",
            "\t Val. Loss: 2.350 |  Val. PPL:  10.485\n",
            "Epoch: 10 | Time: 0m 16s\n",
            "\tTrain Loss: 1.540 | Train PPL:   4.665\n",
            "\t Val. Loss: 2.296 |  Val. PPL:   9.936\n",
            "Epoch: 11 | Time: 0m 16s\n",
            "\tTrain Loss: 1.423 | Train PPL:   4.149\n",
            "\t Val. Loss: 2.254 |  Val. PPL:   9.528\n",
            "Epoch: 12 | Time: 0m 16s\n",
            "\tTrain Loss: 1.337 | Train PPL:   3.807\n",
            "\t Val. Loss: 2.232 |  Val. PPL:   9.322\n",
            "Epoch: 13 | Time: 0m 16s\n",
            "\tTrain Loss: 1.262 | Train PPL:   3.534\n",
            "\t Val. Loss: 2.216 |  Val. PPL:   9.174\n",
            "Epoch: 14 | Time: 0m 16s\n",
            "\tTrain Loss: 1.192 | Train PPL:   3.294\n",
            "\t Val. Loss: 2.193 |  Val. PPL:   8.966\n",
            "Epoch: 15 | Time: 0m 16s\n",
            "\tTrain Loss: 1.128 | Train PPL:   3.089\n",
            "\t Val. Loss: 2.191 |  Val. PPL:   8.945\n",
            "Epoch: 16 | Time: 0m 16s\n",
            "\tTrain Loss: 1.071 | Train PPL:   2.918\n",
            "\t Val. Loss: 2.171 |  Val. PPL:   8.764\n",
            "Epoch: 17 | Time: 0m 16s\n",
            "\tTrain Loss: 1.027 | Train PPL:   2.793\n",
            "\t Val. Loss: 2.183 |  Val. PPL:   8.872\n",
            "Epoch: 18 | Time: 0m 16s\n",
            "\tTrain Loss: 0.985 | Train PPL:   2.677\n",
            "\t Val. Loss: 2.160 |  Val. PPL:   8.669\n",
            "Epoch: 19 | Time: 0m 16s\n",
            "\tTrain Loss: 0.937 | Train PPL:   2.553\n",
            "\t Val. Loss: 2.187 |  Val. PPL:   8.907\n",
            "Epoch: 20 | Time: 0m 16s\n",
            "\tTrain Loss: 0.905 | Train PPL:   2.473\n",
            "\t Val. Loss: 2.200 |  Val. PPL:   9.029\n",
            "Epoch: 21 | Time: 0m 16s\n",
            "\tTrain Loss: 0.871 | Train PPL:   2.389\n",
            "\t Val. Loss: 2.155 |  Val. PPL:   8.626\n",
            "Epoch: 22 | Time: 0m 16s\n",
            "\tTrain Loss: 0.841 | Train PPL:   2.319\n",
            "\t Val. Loss: 2.182 |  Val. PPL:   8.861\n",
            "Epoch: 23 | Time: 0m 16s\n",
            "\tTrain Loss: 0.810 | Train PPL:   2.249\n",
            "\t Val. Loss: 2.189 |  Val. PPL:   8.923\n",
            "Epoch: 24 | Time: 0m 16s\n",
            "\tTrain Loss: 0.778 | Train PPL:   2.177\n",
            "\t Val. Loss: 2.177 |  Val. PPL:   8.819\n",
            "Epoch: 25 | Time: 0m 16s\n",
            "\tTrain Loss: 0.754 | Train PPL:   2.126\n",
            "\t Val. Loss: 2.201 |  Val. PPL:   9.037\n",
            "Epoch: 26 | Time: 0m 16s\n",
            "\tTrain Loss: 0.739 | Train PPL:   2.094\n",
            "\t Val. Loss: 2.199 |  Val. PPL:   9.013\n",
            "Epoch: 27 | Time: 0m 16s\n",
            "\tTrain Loss: 0.713 | Train PPL:   2.041\n",
            "\t Val. Loss: 2.198 |  Val. PPL:   9.008\n",
            "Epoch: 28 | Time: 0m 16s\n",
            "\tTrain Loss: 0.697 | Train PPL:   2.007\n",
            "\t Val. Loss: 2.207 |  Val. PPL:   9.089\n",
            "Epoch: 29 | Time: 0m 16s\n",
            "\tTrain Loss: 0.680 | Train PPL:   1.974\n",
            "\t Val. Loss: 2.205 |  Val. PPL:   9.072\n",
            "Epoch: 30 | Time: 0m 16s\n",
            "\tTrain Loss: 0.655 | Train PPL:   1.924\n",
            "\t Val. Loss: 2.210 |  Val. PPL:   9.119\n",
            "Epoch: 31 | Time: 0m 16s\n",
            "\tTrain Loss: 0.639 | Train PPL:   1.894\n",
            "\t Val. Loss: 2.234 |  Val. PPL:   9.333\n",
            "Epoch: 32 | Time: 0m 16s\n",
            "\tTrain Loss: 0.624 | Train PPL:   1.867\n",
            "\t Val. Loss: 2.250 |  Val. PPL:   9.488\n",
            "Epoch: 33 | Time: 0m 16s\n",
            "\tTrain Loss: 0.607 | Train PPL:   1.834\n",
            "\t Val. Loss: 2.231 |  Val. PPL:   9.308\n",
            "Epoch: 34 | Time: 0m 16s\n",
            "\tTrain Loss: 0.598 | Train PPL:   1.818\n",
            "\t Val. Loss: 2.243 |  Val. PPL:   9.420\n",
            "Epoch: 35 | Time: 0m 16s\n",
            "\tTrain Loss: 0.583 | Train PPL:   1.791\n",
            "\t Val. Loss: 2.267 |  Val. PPL:   9.652\n",
            "Epoch: 36 | Time: 0m 16s\n",
            "\tTrain Loss: 0.577 | Train PPL:   1.781\n",
            "\t Val. Loss: 2.247 |  Val. PPL:   9.464\n",
            "Epoch: 37 | Time: 0m 16s\n",
            "\tTrain Loss: 0.557 | Train PPL:   1.745\n",
            "\t Val. Loss: 2.285 |  Val. PPL:   9.825\n",
            "Epoch: 38 | Time: 0m 16s\n",
            "\tTrain Loss: 0.548 | Train PPL:   1.731\n",
            "\t Val. Loss: 2.287 |  Val. PPL:   9.844\n",
            "Epoch: 39 | Time: 0m 16s\n",
            "\tTrain Loss: 0.535 | Train PPL:   1.708\n",
            "\t Val. Loss: 2.295 |  Val. PPL:   9.922\n",
            "Epoch: 40 | Time: 0m 16s\n",
            "\tTrain Loss: 0.524 | Train PPL:   1.689\n",
            "\t Val. Loss: 2.296 |  Val. PPL:   9.933\n",
            "Epoch: 41 | Time: 0m 16s\n",
            "\tTrain Loss: 0.517 | Train PPL:   1.677\n",
            "\t Val. Loss: 2.314 |  Val. PPL:  10.116\n",
            "Epoch: 42 | Time: 0m 16s\n",
            "\tTrain Loss: 0.505 | Train PPL:   1.657\n",
            "\t Val. Loss: 2.322 |  Val. PPL:  10.199\n",
            "Epoch: 43 | Time: 0m 16s\n",
            "\tTrain Loss: 0.493 | Train PPL:   1.637\n",
            "\t Val. Loss: 2.324 |  Val. PPL:  10.214\n",
            "Epoch: 44 | Time: 0m 16s\n",
            "\tTrain Loss: 0.484 | Train PPL:   1.622\n",
            "\t Val. Loss: 2.329 |  Val. PPL:  10.269\n",
            "Epoch: 45 | Time: 0m 16s\n",
            "\tTrain Loss: 0.480 | Train PPL:   1.616\n",
            "\t Val. Loss: 2.364 |  Val. PPL:  10.629\n",
            "Epoch: 46 | Time: 0m 16s\n",
            "\tTrain Loss: 0.473 | Train PPL:   1.604\n",
            "\t Val. Loss: 2.350 |  Val. PPL:  10.490\n",
            "Epoch: 47 | Time: 0m 16s\n",
            "\tTrain Loss: 0.469 | Train PPL:   1.599\n",
            "\t Val. Loss: 2.354 |  Val. PPL:  10.526\n",
            "Epoch: 48 | Time: 0m 16s\n",
            "\tTrain Loss: 0.456 | Train PPL:   1.578\n",
            "\t Val. Loss: 2.352 |  Val. PPL:  10.507\n",
            "Epoch: 49 | Time: 0m 16s\n",
            "\tTrain Loss: 0.452 | Train PPL:   1.571\n",
            "\t Val. Loss: 2.389 |  Val. PPL:  10.908\n",
            "Epoch: 50 | Time: 0m 16s\n",
            "\tTrain Loss: 0.443 | Train PPL:   1.558\n",
            "\t Val. Loss: 2.353 |  Val. PPL:  10.513\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCoO9QRr2MvM"
      },
      "source": [
        "!cp tut6-model.pt '/content/drive/MyDrive/1-Projects/END/week14/capstone'"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieIjql9uPKH1"
      },
      "source": [
        "def generate_code(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()\n",
        "        \n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKmomDC33Fob",
        "outputId": "813a0368-db1a-4a32-f800-0260e5436734"
      },
      "source": [
        "input_text = 'program to sort a list of dictionaries by key'\n",
        "\n",
        "print(input_text)\n",
        "\n",
        "code_snippet, attention = generate_code(input_text, SRC, TRG, model, device)\n",
        "\n",
        "for i in range(len(code_snippet)):\n",
        "  print(end =\"\")\n",
        "  print(code_snippet[i])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "program to sort a list of dictionaries by key\n",
            "\n",
            "\n",
            "test_list\n",
            "=\n",
            "[\n",
            "\"\n",
            "gfg\n",
            "\"\n",
            ",\n",
            "\"\n",
            "  \n",
            "\"\n",
            ",\n",
            "\"\n",
            "is\n",
            "\"\n",
            ",\n",
            "\"\n",
            "best\n",
            "\"\n",
            ",\n",
            "\"\n",
            "for\n",
            "\"\n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "print(\"the\n",
            "original\n",
            "list\n",
            "is\n",
            ":\n",
            "\"\n",
            "+\n",
            "str(test_list\n",
            ")\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "k\n",
            "=\n",
            "2\n",
            "\n",
            "\n",
            "\n",
            "res\n",
            "=\n",
            "list\n",
            "(\n",
            "filter(none\n",
            ",\n",
            "test_list))[-k\n",
            "]\n",
            "\n",
            "\n",
            "\n",
            "print(\"the\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}